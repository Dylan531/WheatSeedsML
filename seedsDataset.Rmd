---
title: "seedsDataset"
author: "Dylan & Johannes"
date: "4/18/2022"
output: html_document
---



## dataframes 
```{r}
library(keras)
library(tfdatasets)
library(caret)

#Loading a csv file
seedsdf <- read.csv("seeds_dataset.csv")
seedsdfProcessed <- read.csv("seeds_dataset.csv")

# Various syntax for R dataframes
summary(seedsdf)

head(seedsdf)

# You can refer to columns by name or by number:
head(seedsdf[1]) # head takes the first few elements

head(seedsdf$area)

head(seedsdf["area"])




 for (i in 1:7) {
  min <- min(seedsdf[,i])
  max <- max(seedsdf[,i])
  for (j in 1:length(seedsdf[,i])) { 
    seedsdfProcessed[j,i] <- ((seedsdf[j,i]-min)/(max-min))+1
    print(seedsdfProcessed[j,i])
  }
}
```
## Explore the distributions of feature values using kernel density plots
If multiple distributions are visible, a particular distribution may be associated with a category. 
```{r}
for (i in 1:7) {
  plot(density(seedsdf[,i]))
  plot(density(seedsdfProcessed[,i]))
}

```
## Explore correlation among features
We should select one feature among each group of highly correlated features (>0.7?).
```{r}
# Use the R correlation function cor()
# The all.obs option assumes our data frame has no missing values. Uses Pearson correlation testing by default.
cor(seedsdf)

```


```{r}
#You can refer to rows by numbers, note difference from columns:
#seedsdf[5,]

#Ranges of columns:
#head(seedsdf[1:3])

#Ranges of rows:
#seedsdf[1:3,]
```


## Splitting data into training and testing

```{r}
sample_size <- 150
layer.units <- 128
model.loss <- "categorical_crossentropy"
model.optimizer <- "adam"
model.accuracy <- "accuracy"
model.epochs <- 50
input.shape <- 3
training.subset <- c("area","asymmetry.cof","compactness")
set.seed(1234) # setting random seed to make results repeatable
tf.random.set_seed(1234)

picked <- sample(seq_len(nrow(seedsdfProcessed)),size = sample_size)
training <- seedsdf[picked,]
testing <- seedsdf[-picked,]


# Changing y into categorical data (performing one-hot encoding)

yTr <- to_categorical(training$variety, num_classes = 7)
yTest <- to_categorical(testing$variety, num_classes = 7)

```

## Neural network for the iris example

```{r}
model = keras_model_sequential() %>%
  layer_dense(units = layer.units, activation = "relu",input_shape=input.shape) %>%
  layer_dense(units = layer.units, activation = "relu") %>%
  layer_dense(units = ncol(yTr), activation = "softmax")


model %>% compile(
  loss = model.loss,
  optimizer = model.optimizer, #optimizer_rmsprop(),
  metrics = model.accuracy
)

xTr <- as.matrix(training[,training.subset]) # need to convert to a matrix
xTest <- as.matrix(testing[,training.subset])

model %>% 
  fit(
    x = xTr, # input is the first 7 columns of the dataframe
    y = yTr, # label is the last column
    epochs = model.epochs
  )

```

# Evaluate the model
```{r}
model %>% evaluate(xTest, yTest)

# Predicting likelihood of all categories:
result <- model %>% predict(xTest)

result

testing[,8]

```
