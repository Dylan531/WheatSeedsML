---
title: "Wheat Grain Dataset"
author: "Dylan, Michael, and  Johannes"
date: "4/18/2022"
output: html_document
---

## dataframes 
```{r}
library(keras)
library(tfdatasets)

# Loading a csv file
seedsdf <- read.csv("seeds_dataset.csv")
scaled_df <- read.csv("seeds_dataset.csv")

# Various syntax for R dataframes
summary(seedsdf)

# Normalize data between 1 and 2
for (i in 1:7) {
  min <- min(seedsdf[, i])
  max <- max(seedsdf[, i])
  for (j in 1:length(seedsdf[, i])) {
    scaled_df[j, i] <- ((seedsdf[j, i] - min) / (max - min)) + 1
  }
}
```

## Explore the distributions of feature values using kernel density plots
If multiple distributions are visible, a particular distribution may be associated with a category. 
```{r}
for (i in 1:7) {
  plot(density(scaled_df[, i]), names(scaled_df)[i])
}
```

## Explore correlation among features
We should select one feature among each group of highly correlated features (>0.7?).
```{r}
# Use the R correlation function cor()
# The all.obs option assumes our data frame has no missing values. Uses Pearson
# correlation testing by default.
write.table(round(cor(seedsdf), 3),
  file = "feature_correlations.csv", sep = ",", append = F,
  row.names = T, col.names = T
)
```

## Train and test repeatedly
```{r, include=FALSE} 
loss_vect = c()
accuracy_vect = c()
sample_size <- 160
layer_units <- 128
model_loss <- "categorical_crossentropy"
model_optimizer <- "adam"
model_accuracy <- "accuracy"
model_epochs <- 120
select_df <- scaled_df[, c("Area", "Compactness", "Groove.Length", "Variety")]
test_comment <- "Three hidden layers"

for(i in 1:5) {
  set.seed(i) # setting random seed to make results repeatable and fair between models
  
  picked <- sample(seq_len(nrow(select_df)), size = sample_size)
  training <- select_df[picked, ]
  testing <- select_df[-picked, ]
  
  # Changing y into categorical data (performing one-hot encoding)
  training$Variety <- training$Variety - 1 # Standard is category count from 0
  testing$Variety <- testing$Variety - 1
  shape <- length(training) - 1
  y_tr <- to_categorical(training$Variety, num_classes = 3)
  y_test <- to_categorical(testing$Variety, num_classes = 3)
  
  ## Neural Network
  model <- keras_model_sequential() %>%
    layer_dense(units = layer_units, activation = "relu", input_shape = (shape) ) %>%
    layer_dense(units = layer_units, activation = "relu") %>%
    layer_dense(units = layer_units, activation = "relu") %>%
    layer_dense(units = layer_units, activation = "relu") %>%
    layer_dense(units = ncol(y_tr), activation = "softmax")
  
  model %>% compile(
    loss = model_loss,
    optimizer = model_optimizer, # optimizer_rmsprop(),
    metrics = model_accuracy
  )
  
  x_tr <- as.matrix(training[, 1:(length(training) -1)]) # need to convert to a matrix
  x_test <- as.matrix(testing[, 1:(length(training) -1)])
  
  model %>%
    fit(
      x = x_tr, # input is the training subsets
      y = y_tr, # label is the last column
      epochs = model_epochs
    )
  
  # Test neural network
  score <- model %>% evaluate(x_test, y_test, verbose = 0)

  loss_vect[i] <- round(score[1], 4)
  accuracy_vect[i] <- round(score[2], 4)
}


```

# Evaluate the model and record data
```{r}
testComment <- "Randomnized data selection between each run"

# Predicting likelihood of all categories:
# result <- model %>% predict(x_test)

# result

# testing[, 8]

# Table Data
variable_content <- c(
  sample_size, layer_units, model_loss, model_optimizer,
  model_accuracy, model_epochs, shape, toString(names(training[, 1:(length(training) -1)])),
  median(loss_vect), median(accuracy_vect), test_comment
)
data <- matrix(variable_content, ncol = 11, byrow = TRUE)

#  Table labels
colnames(data) <- c(
  "Sample Size", "Layer Units", "Loss", "Optimizer",
  "Accuracy", "Epochs", "Input Shape", "Feature Selection",
  "Test Loss", "Test Accuracy", "Comment"
)
rownames(data) <- c(" ")
table <- as.table(data)

# Display table
table

# Append run info to testData.csv
write.table(data,
  file = "experiment_history.csv", sep = ",", append = T,
  row.names = F, col.names = F
)

# Clear global memory space
rm(list = ls())
```
