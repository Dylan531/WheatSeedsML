---
title: "Wheat Grain Dataset"
author: "Dylan, Michael, and  Johannes"
date: "4/18/2022"
output: html_document
---



## dataframes 
```{r}
library(keras)
library(tfdatasets)

# Loading a csv file
seedsdf <- read.csv("seeds_dataset.csv")
processed_seedsdf <- read.csv("seeds_dataset.csv")

# Various syntax for R dataframes
summary(seedsdf)

# Normalize data between 1 and 2
for (i in 1:7) {
  min <- min(seedsdf[, i])
  max <- max(seedsdf[, i])
  for (j in 1:length(seedsdf[, i])) {
    processed_seedsdf[j, i] <- ((seedsdf[j, i] - min) / (max - min)) + 1
  }
}
```

## Explore the distributions of feature values using kernel density plots
If multiple distributions are visible, a particular distribution may be associated with a category. 
```{r}
for (i in 1:7) {
  plot(density(processed_seedsdf[, i]), names(processed_seedsdf)[i])
}
```

## Explore correlation among features
We should select one feature among each group of highly correlated features (>0.7?).
```{r}
# Use the R correlation function cor()
# The all.obs option assumes our data frame has no missing values. Uses Pearson
# correlation testing by default.
cor(seedsdf)
write.table(cor(seedsdf),
  file = "feature_correlations.csv", sep = ",", append = F,
  row.names = T, col.names = T
)
```

## Splitting data into training and testing
```{r}
sample_size <- 168
layer_units <- 128
model_loss <- "categorical_crossentropy"
model_optimizer <- "adam"
model_accuracy <- "accuracy"
model_epochs <- 75
input_shape <- 7
training_subset <- 1:7
```

## Neural Network
```{r,include=FALSE}
averageLoss = c()
averageAccuracy = c()

for (i in 1:5) {
  
  set.seed(i) # setting random seed to make results repeatable and fair between models
  
  picked <- sample(seq_len(nrow(processed_seedsdf)), size = sample_size)
  training <- seedsdf[picked, ]
  testing <- seedsdf[-picked, ]
  
  
  # Changing y into categorical data (performing one-hot encoding)
  training$Variety <- training$Variety - 1
  testing$Variety <- testing$Variety - 1
  y_tr <- to_categorical(training$Variety, num_classes = 3)
  y_test <- to_categorical(testing$Variety, num_classes = 3)
  
  
  
  model <- keras_model_sequential() %>%
    layer_dense(units = layer_units, activation = "relu", input_shape = input_shape) %>%
    layer_dense(units = layer_units, activation = "relu", kernel_regularizer = regularizer_l1_l2(l1 = 0.01, l2 = 0.01)) %>%
    layer_dense(units = ncol(y_tr), activation = "softmax")
  
  
  model %>% compile(
    loss = model_loss,
    optimizer = model_optimizer, # optimizer_rmsprop(),
    metrics = model_accuracy
  )
  
  x_tr <- as.matrix(training[, training_subset]) # need to convert to a matrix
  x_test <- as.matrix(testing[, training_subset])
  
  model %>%
    fit(
      x = x_tr, # input is the training subsets
      y = y_tr, # label is the last column
      epochs = model_epochs
    )
  
  score <- model %>% evaluate(x_test, y_test, verbose = 0)

  averageLoss[i] <- round(score[1], 4)
  averageAccuracy[i] <- round(score[2], 4)
}


```

# Evaluate the model
```{r}
testComment <- "Randomnized data selection between each run"

# Predicting likelihood of all categories:
# result <- model %>% predict(x_test)

# result

# testing[, 8]

# Table Data
variable_content <- c(
  sample_size, layer_units, model_loss, model_optimizer,
  model_accuracy, model_epochs, input_shape, toString(training_subset),
  median(averageLoss), median(averageAccuracy), testComment
)
data <- matrix(variable_content, ncol = 11, byrow = TRUE)

#  Table labels
colnames(data) <- c(
  "Sample Size", "Layer Units", "Loss", "Optimizer",
  "Accuracy", "Epochs", "Input Shape", "Feature Selection",
  "Test Loss", "Test Accuracy", "Comment"
)
rownames(data) <- c("")
table <- as.table(data)

# Display table
table

# Append run info to testData.csv
write.table(data,
  file = "experiment_history.csv", sep = ",", append = T,
  row.names = F, col.names = F
)
```
